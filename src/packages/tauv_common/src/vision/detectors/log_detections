#!/usr/bin/env python3

import rospy
from tauv_msgs.msg import Pose, BucketDetection, BucketList, RegisterObjectDetections
from std_msgs.msg import Header
import numpy as numpy
import cv2
from cv_bridge import CvBridge
from darknet_ros_msgs.msg import BoundingBoxes, BoundingBox
from sensor_msgs.msg import Image, CameraInfo
from vision.depth_estimation.depth_estimation import DepthEstimator
from geometry_msgs.msg import Point
from vision.detector_bucket.detector_bucket import Detector_Bucket
import math
from tauv_util import transforms
from tauv_util import types
from scipy.spatial.transform import Rotation
from std_srvs.srv import Trigger

class LogDetections():
    def __init__(self):
        self.cur_position = (0,0,0)
        self.cur_orientation = (0,0,0)

        self.depth_image = None
        self.data = None
        self.created= False

        self.new_image = False

        rospy.init_node('image_detector', anonymous = True)

        self.depth_camera_info = CameraInfo()
        self.bounding_boxes = BoundingBoxes()
        self.cv_bridge = CvBridge()
        self.detector_bucket = Detector_Bucket()

        rospy.wait_for_message("/darknet_ros/bounding_boxes", BoundingBoxes)
        
        rospy.Subscriber("/zedm_A/zed_node_A/depth/depth_registered",Image,self.depth_callback)
        rospy.Subscriber("/zedm_A/zed_node_A/left/camera_info",CameraInfo, self.camera_info_callback)
        rospy.Subscriber("/darknet_ros/bounding_boxes", BoundingBoxes, self.bbox_callback)
        rospy.Subscriber("/color_detector", BoundingBoxes, self.bbox_callback)
        self.detector = rospy.Publisher("register_object_detection", RegisterObjectDetections,
                                              queue_size=10)
        
        rospy.Service("/bucket/reset", Trigger, self.reset)

        rospy.Timer(rospy.Duration(2),self.publish)

        rospy.Subscriber("gnc/pose", Pose, self.update_position)
        
    def reset(self, srv):
        self.detector_bucket.reset()

    def publish(self, event):
        self.detector_bucket.publish_all()

    def find(self, tag):
        return self.detector_bucket.find_by_tag(tag)

    def update_position(self,data):
        self.cur_position = (data.position.x, data.position.y, data.position.z)
        self.cur_orientation = (data.orientation.x, data.orientation.y, data.orientation.z)

    def camera_info_callback(self, msg):
        self.depth_camera_info = msg

    def depth_callback(self, msg):
        self.depth_image = self.cv_bridge.imgmsg_to_cv2(msg, "passthrough")
        self.created=True

    def calc_pos(self, relative, cur_orientation, cur_position):

        roll = cur_orientation [0]
        pitch = cur_orientation [1]
        yaw = cur_orientation [2]

        relative = numpy.array([relative[2] + 0.465, relative[0], relative[1]])

        rpy = numpy.array([[math.cos(pitch)*math.cos(yaw), -math.cos(roll)*math.sin(yaw)+math.cos(yaw)*math.sin(pitch)*math.sin(roll), math.sin(roll)*math.sin(yaw)+math.cos(roll)*math.sin(pitch)*math.cos(yaw)],
        [math.cos(pitch)*math.sin(yaw), math.cos(roll)*math.cos(yaw)+math.sin(roll)*math.sin(pitch)*math.sin(yaw), -math.sin(roll)*math.cos(yaw)+math.cos(roll)*math.sin(pitch)*math.sin(yaw)],
        [-math.sin(pitch), math.sin(roll)*math.cos(pitch), math.cos(roll)*math.cos(pitch)]])

        return array_to_point(cur_position+numpy.matmul(rpy, relative))


    def invalid_pos(self, objdet):
        if(numpy.isnan(objdet.position.x) or numpy.isnan(objdet.position.y) or numpy.isnan(objdet.position.z)):
            return True
        
        if(objdet.position.z>0):
            return True
    
        return False


    def bbox_callback(self, bboxes):
        if(not self.created):
            return

        sub_or = self.cur_orientation
        sub_pos = self.cur_position

        objects = RegisterObjectDetections()
        objects.objdets = list()

        for bbox in bboxes.bounding_boxes:
            objdet = BucketDetection()

            objdet.tag = bbox.Class

            if(not self.created):
                continue

            relative_pos = DepthEstimator.estimate_absolute_depth(self.depth_image, bbox, self.depth_camera_info)

            if(relative_pos == numpy.nan):
                continue

            objdet.position = self.calc_pos(relative_pos, sub_or, sub_pos)

            if(self.invalid_pos(objdet)):
               continue
        
            objects.objdets.append(objdet)

        objects.detector_tag = "camera"

        self.detector.publish(objects)

def array_to_point(arr):
    p = Point()
    p.x = arr[0]
    p.y = arr[1]
    p.z = arr[2]
    return p

def listen():
    s = LogDetections()
    rospy.spin()

if __name__=='__main__':
    listen()
